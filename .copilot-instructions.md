# Copilot Instructions for pplx-sdk

## Code Style & Standards

### Python Version
- Target: **Python 3.12+** only
- Type hints on **all** functions (100% coverage)
- Docstrings: **Google style** on all public classes/methods

### Linting & Formatting
```bash
ruff format . && ruff check --fix .
mypy pplx_sdk --strict
```

### Imports
- Use `from __future__ import annotations` at top of modules
- Standard library â†’ typing â†’ external packages â†’ local imports
- `isort` compatible (black profile, line length 100)

### Naming
- Classes: PascalCase (PerplexityClient, SSETransport)
- Functions/methods: snake_case
- Constants: UPPER_SNAKE_CASE
- Private: _leading_underscore

## Module Requirements

### domain/models.py
- Use Pydantic v2 BaseModel or @dataclass
- Include Field() with descriptions for validation
- Include @property helpers (e.g., Entry.text)
- Include @classmethod constructors (e.g., Entry.from_chunk)
- Preserve exact field names from Perplexity API

### transport/http.py
- Wrap httpx.Client (not requests)
- Support context manager (__enter__, __exit__)
- Preserve headers across requests
- Method signature: request(method, path, params, json, headers)
- Return httpx.Response directly

### transport/sse.py
- Parse SSE format exactly:
  ```
  event: type_name\ndata: {json}\n\n
  ```
- Handle `:` comments and empty lines
- Stop on `[end]` marker
- Yield MessageChunk per event
- Skip empty lines and comments

### domain/entries.py
- stream_ask() â†’ Generator[MessageChunk, None, None]
- ask() â†’ Entry (consumes full stream, returns last)
- Support extra kwargs forwarding
- Pass context_uuid, frontend_uuid to SSE

### client.py
- PerplexityClient:
  - __init__(api_base, auth_token, timeout, default_headers)
  - Properties: .threads, .entries, .memories, .collections, .articles
  - Methods: new_conversation(), conversation_from_thread()
  - Context manager: close(), __enter__, __exit__

- Conversation (dataclass):
  - Fields: client, thread, entries
  - @property context_uuid â†’ thread.context_uuid
  - @property last_entry â†’ entries[-1] or None
  - ask_stream(...) â†’ Generator[MessageChunk]
  - ask(...) â†’ Entry (appends to self.entries)
  - fork(from_entry) â†’ Conversation (new thread)
  - save_to_collection(id)
  - to_article()

### api/oai_server.py
- FastAPI app instance
- Endpoints:
  - POST /v1/chat/completions (streaming)
  - GET /v1/models (list available)
  - GET /v1/health
- Map OpenAI models to Perplexity models
- Convert ChatCompletionRequest â†’ PerplexityClient.ask_stream()
- Convert MessageChunk â†’ ChatCompletionChunk (SSE format)
- Handle Bearer token auth

### streaming/manager.py
- StreamManager(max_retries, retry_backoff_ms, timeout_ms)
- stream(query, context_uuid, ...) â†’ Generator[MessageChunk]
- Extract cursor from final_response
- Implement exponential backoff: delay_ms = base * (2 ^ attempt)
- Support resume with resumeentryuuids + cursor
- Enforce timeout_ms hard limit

## Critical Behaviors

### SSE Parsing
1. Read line-by-line from streaming response
2. Skip lines starting with `:` (comments)
3. Parse `event: type_name` lines
4. Parse `data: {json}` lines â†’ json.loads()
5. Stop on `[end]` marker
6. Yield MessageChunk for each data: line

### Stream Lifecycle
```python
for chunk in stream_ask(...):
    if chunk.type == "answer_chunk":
        print(chunk.text)  # Partial token
    elif chunk.type == "final_response":
        entry = Entry.from_chunk(chunk)  # Full response
        print(entry.text)  # Complete answer
```

### Conversation State
```python
conv = client.new_conversation()
entry1 = conv.ask("Q1")  # â†’ appended to conv.entries
entry2 = conv.ask("Q2", parent_entry_uuid=entry1.backend_uuid)  # threaded

forked = conv.fork(entry1)  # new thread, cloned at entry1
forked.ask("Different path...")  # separate conversation
```

### OpenAI Compat
```python
# Request
{"model": "gpt-4-turbo", "messages": [{"role": "user", "content": "..."}]}
â†“
# Internally maps to
add_stream(query="...", model_preference="pplx-70b-deep")
â†“
# Response
data: {"choices": [{"delta": {"content": "token"}}]}  # Per chunk
data: {"choices": [{"delta": {}}]}  # [DONE] marker equivalent
```

## Testing Requirements

### Fixtures (tests/fixtures/)
- Mock SSE responses in text/event-stream format
- Include complete lifecycle: progress â†’ chunk â†’ final_response
- Include error responses for retry testing

### Unit Tests (pytest)
```python
def test_http_transport_request():
    # Use pytest-httpx mock
    pass

def test_sse_parsing():
    # Parse real SSE format
    pass

def test_conversation_threaded():
    # Verify parent_entry_uuid tracking
    pass

def test_stream_retry_backoff():
    # Verify exponential backoff
    pass
```

## Error Handling

### HTTP Errors
- 401: Re-raise with "Invalid session token"
- 429: Trigger exponential backoff
- 500+: Retry with backoff
- Network error: Retry with backoff

### SSE Errors
- JSON parse error: Log, skip, continue
- Missing required fields: Use defaults
- Stream timeout: Raise TimeoutError
- Empty stream: Raise RuntimeError("Empty stream")

## Special Cases

### Resume on Disconnect
```python
# Server returns cursor in final_response
cursor = chunk.data.get("cursor")

# Next request includes:
payload["resume_entry_uuids"] = [entry_id]
payload["cursor"] = cursor

# Server resumes from checkpoint
```

### Parent Entry Threading
```python
# User asks follow-up:
conv.ask("Q2")  # Internally:
payload["parent_entry_uuid"] = conv.last_entry.backend_uuid
```

### Fork Behavior
```python
forked = conv.fork(entry1)
# New thread, but conversation continues at entry1
# entry1 â†’ multiple continuations possible
```

## PR Checklist

Before creating PR:
- [ ] Type hints: `mypy pplx_sdk` passes
- [ ] Formatting: `ruff format .` applied
- [ ] Linting: `ruff check --fix .` passes
- [ ] Tests: `pytest tests/` passes with >80% coverage
- [ ] Docstrings: Google style on all public APIs
- [ ] No hardcoded values except defaults
- [ ] Handles edge cases (empty streams, timeouts, etc)
- [ ] Examples run without errors

## Resources

- **SSE Spec**: https://html.spec.whatwg.org/multipage/server-sent-events.html
- **Pydantic v2**: https://docs.pydantic.dev/latest/
- **httpx**: https://www.python-httpx.org/
- **FastAPI**: https://fastapi.tiangolo.com/
- **Perplexity API**: See README.md, SSE request/response reference

## Communication

- Issues: Detailed acceptance criteria in #2
- PRs: Link to issue, include test results
- Questions: Ask before implementing
- Blockers: Flag early (auth, API changes, etc)

Good luck! ðŸš€
